{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb94eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3a84cbf",
   "metadata": {},
   "source": [
    "### Implemented a self-training system using a K-nearest neighbor classifier for this problem (to evaluate the level of certainty for each prediction on unlabeled data, I used the purity of the prediction - i.e. how many more ”votes” the predicted class received than the other class - and I used the distance weighted voting where the number of votes each of the K data points receives is inversely proportional to the distance from the data point). The algorithm allows to change the number of data items that are being added to the labeled data set in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1995da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_distance(sample, inputs):\n",
    "    \n",
    "    diff = sample - inputs\n",
    "    sum_pow = np.sum(np.power(diff, 2), axis=1)\n",
    "    \n",
    "    return np.power(sum_pow, 0.5)\n",
    "\n",
    "def classify(k, sorted_labels):\n",
    "    \n",
    "    k_neighbors = sorted_labels[:k]\n",
    "    men_occurencies = np.count_nonzero(k_neighbors == ' M')\n",
    "    women_occurencies = np.count_nonzero(k_neighbors == ' W')\n",
    "    probability = max(men_occurencies, women_occurencies)/k\n",
    "    \n",
    "    return ' M' if men_occurencies > women_occurencies else ' W', probability\n",
    "\n",
    "def KNN_classification(sample, k, df):\n",
    "\n",
    "    labels = df['Class'].values\n",
    "    inputs = df.drop('Class', axis=1).values\n",
    "\n",
    "    cart_distance = cartesian_distance(sample, inputs)\n",
    "\n",
    "    labeled_cart = np.vstack((cart_distance, labels))\n",
    "\n",
    "    sorted_cart = labeled_cart.T[labeled_cart.T[:, 0].argsort()]\n",
    "    sorted_labels = sorted_cart.T[1]\n",
    "\n",
    "    return classify(k, sorted_labels)\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e3971e1",
   "metadata": {},
   "source": [
    "### Learned a classifier using the semi-supervised learning algorithm and compared it against the K-nearest neighbor classifier learned only from the labeled data Ds by evaluating the fraction of initially unlabeled points it predicts correctly (for the self-learning you can simply use the fraction of the initially unlabeled points that were assigned the correct label during the learning process). Repeated the comparison for four different numbers of data points added in each iteration, including adding 1 data point in each iteration, adding all data points in the first iteration, adding 5 points in each iteration, and one setting of random choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6baa6885",
   "metadata": {},
   "source": [
    "### 1) adding data points based on the constraint i.e (Probablities > confidence). Probabilities were defined based on the majority of the votes of the particular class and the total number of neigboring points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b5c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2c.csv')\n",
    "labeled_data = df.iloc[:20,:]\n",
    "unlabeled_data = df.iloc[20:,:-1].reset_index(drop = True)\n",
    "actual_labels = df.iloc[20:,-1].values\n",
    "\n",
    "k = 5\n",
    "confidence = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b35d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the semi-supervised learning algorithm by adding data based on the constraint considering probabilities higher than the confidence provided: 0.7560975609756098\n"
     ]
    }
   ],
   "source": [
    "y_actual = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    probabilities = []\n",
    "    predictions = []\n",
    "    indexes = []\n",
    "\n",
    "    for sample in unlabeled_data.values:\n",
    "        prediction_1, probability = KNN_classification(sample, k, labeled_data)\n",
    "        probabilities.append(probability)\n",
    "        predictions.append(prediction_1)\n",
    "\n",
    "    indexes = np.where(np.array(probabilities) > confidence) #indexes where probabilities is greater than confidence\n",
    "    \n",
    "    if len(indexes[0]) == 0:\n",
    "        break\n",
    "        \n",
    "    for x in indexes[0]:\n",
    "        y_actual.append(actual_labels[x]) #Append the actual labels from the index where proability is greater than confidence\n",
    "        \n",
    "    pred = [predictions[i] for i in indexes[0]]  # Prediction at the indexes where p>c\n",
    "\n",
    "    new_data = unlabeled_data.iloc[indexes[0],:].copy() # new data points to add from unlabeled data to training data wrp to the indexes fetched\n",
    "    new_data['Class'] = pred\n",
    "\n",
    "    labeled_data = pd.concat([labeled_data, new_data]).reset_index(drop = True) #updated training\n",
    "    unlabeled_data = unlabeled_data.drop(indexes[0], axis = 0).reset_index(drop = True) #updated unlabeled\n",
    "\n",
    "y_pred = labeled_data.iloc[20:,-1].values\n",
    "\n",
    "print(f\"Accuracy of the semi-supervised learning algorithm by adding data based on the constraint considering probabilities higher than the confidence provided: {accuracy_metric(y_actual, y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a933aa65",
   "metadata": {},
   "source": [
    "### 2) adding 1 data point in each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "783392e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = df.iloc[:20,:]\n",
    "unlabeled_data = df.iloc[20:,:-1].reset_index(drop = True)\n",
    "actual_labels = df.iloc[20:,-1].values\n",
    "\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7d7d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of the semi-supervised learning algorithm by adding 1 data point in each iteration: 0.63\n"
     ]
    }
   ],
   "source": [
    "y_actual = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    probabilities = []\n",
    "    predictions = []\n",
    "    for sample in unlabeled_data.values:\n",
    "        prediction_1, probability = KNN_classification(sample, k, labeled_data)\n",
    "        probabilities.append(probability)\n",
    "        predictions.append(prediction_1)\n",
    "\n",
    "    sort_index = np.flip(np.argsort(probabilities))\n",
    "\n",
    "    if len(sort_index)==0:\n",
    "        break\n",
    "    \n",
    "    y_actual.append(actual_labels[sort_index[0]])\n",
    "    pred = [predictions[i] for i in sort_index]\n",
    "\n",
    "    new_data = unlabeled_data.iloc[sort_index[0],:].copy()\n",
    "    new_data['Class'] = pred[0]\n",
    "    labeled_data = labeled_data.append(new_data, ignore_index = True)\n",
    "    unlabeled_data = unlabeled_data.drop(sort_index[0], axis = 0).reset_index(drop = True)\n",
    "    \n",
    "y_pred = labeled_data.iloc[20:,-1].values\n",
    "\n",
    "print(f\" Accuracy of the semi-supervised learning algorithm by adding 1 data point in each iteration: {accuracy_metric(y_actual, y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b719528e",
   "metadata": {},
   "source": [
    "### 3) adding 5 points in each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a2b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = df.iloc[:20,:]\n",
    "unlabeled_data = df.iloc[20:,:-1].reset_index(drop = True)\n",
    "actual_labels = df.iloc[20:,-1].values\n",
    "\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "200c400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of the semi-supervised learning algorithm by adding 5 data points in each iteration: 0.52\n"
     ]
    }
   ],
   "source": [
    "y_actual = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "    probabilities = []\n",
    "    predictions = []\n",
    "    for sample in unlabeled_data.values:\n",
    "        prediction_1, probability = KNN_classification(sample, k, labeled_data)\n",
    "        probabilities.append(probability)\n",
    "        predictions.append(prediction_1)\n",
    "\n",
    "    sort_index = np.flip(np.argsort(probabilities))\n",
    "    \n",
    "    if len(sort_index)==0:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    for x in sort_index[:5]:\n",
    "        y_actual.append(actual_labels[x])\n",
    "\n",
    "    pred = [predictions[i] for i in sort_index]\n",
    "\n",
    "    new_data = unlabeled_data.iloc[sort_index[:5],:].copy()\n",
    "    new_data['Class'] = pred[:5]\n",
    "    labeled_data = labeled_data.append(new_data, ignore_index = True)\n",
    "    unlabeled_data = unlabeled_data.drop(sort_index[:5], axis = 0).reset_index(drop = True)\n",
    "    \n",
    "y_pred = labeled_data.iloc[20:,-1].values\n",
    "\n",
    "print(f\" Accuracy of the semi-supervised learning algorithm by adding 5 data points in each iteration: {accuracy_metric(y_actual, y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc6bbdc0",
   "metadata": {},
   "source": [
    "### 4) adding all data points in the first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d3eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = df.iloc[:20,:]\n",
    "unlabeled_data = df.iloc[20:,:-1].reset_index(drop = True)\n",
    "actual_labels = df.iloc[20:,-1].values\n",
    "\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b10ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy of the semi-supervised learning algorithm by adding all data points in each iteration: 0.77\n"
     ]
    }
   ],
   "source": [
    "y_actual = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "    probabilities = []\n",
    "    predictions = []\n",
    "    for sample in unlabeled_data.values:\n",
    "        prediction_1, probability = KNN_classification(sample, k, labeled_data)\n",
    "        probabilities.append(probability)\n",
    "        predictions.append(prediction_1)\n",
    "\n",
    "    sort_index = np.flip(np.argsort(probabilities))\n",
    "    \n",
    "    if len(sort_index)==0:\n",
    "        break\n",
    "    \n",
    "    for x in sort_index[:100]:\n",
    "        y_actual.append(actual_labels[x])\n",
    "    \n",
    "    pred = [predictions[i] for i in sort_index]\n",
    "\n",
    "    new_data = unlabeled_data.iloc[sort_index[:100],:].copy()\n",
    "    new_data['Class'] = pred[:100]\n",
    "    labeled_data = labeled_data.append(new_data, ignore_index = True)\n",
    "    unlabeled_data = unlabeled_data.drop(sort_index[:100], axis = 0).reset_index(drop = True)\n",
    "    \n",
    "y_pred = labeled_data.iloc[20:,-1].values\n",
    "\n",
    "print(f\" Accuracy of the semi-supervised learning algorithm by adding all data points in each iteration: {accuracy_metric(y_actual, y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5326e8d1",
   "metadata": {},
   "source": [
    "### Using KNN Classifier (Supervised Learning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49df13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2c.csv')\n",
    "labeled_data = df.iloc[:20,:]\n",
    "unlabeled_data = df.iloc[20:,:-1].reset_index(drop = True)\n",
    "actual_labels = df.iloc[20:,-1].values\n",
    "\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b568317",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for sample in unlabeled_data.values:\n",
    "    prediction_1, probabilities = KNN_classification(sample, k, labeled_data)\n",
    "    predictions.append(prediction_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d966a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(actual_labels, predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c6d1265",
   "metadata": {},
   "source": [
    "### Discuss if you see any performance difference and if so, what it is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "197eb103",
   "metadata": {},
   "source": [
    "Accuracy of the semi-supervised learning algorithm by adding data based on the constraint considering probabilities higher than the confidence provided: 0.7560975609756098 <br>\n",
    "Accuracy of the semi-supervised learning algorithm by adding 1 data point in each iteration: 0.63 <br>\n",
    "Accuracy of the semi-supervised learning algorithm by adding 5 data points in each iteration: 0.52 <br>\n",
    "Accuracy of the semi-supervised learning algorithm by adding all data points in each iteration: 0.77 <br>\n",
    "\n",
    "From the above results using k=5 neighboring data points and four different methods of adding data points it can be inferred that by adding the data points based on the constraint i.e considering the probabilities of the class and adding the data points that has probabilties higher than the confidence has given better results than that of other methods. This was because the training data was getting the data points whose labels were close to that of actual labels. For this, we haven't set the predetermined number of data points to add so it got more data datapoints to train on comparatively and hence performing better than adding one datapoint and five data points in one iteration. Moreover, using all the data points in the single iteration and predicting the labels on these data points will give the same results as that of KNN classifier used in supervised learning i.e with the known data labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
